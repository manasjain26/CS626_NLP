{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs626_final_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eb81b90864144cd5adecce819b7483b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d7916a6d0e0842489cc12a70ccdb4ad0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a6f6f17bb9c5401ca8b5f2ebfca3721f",
              "IPY_MODEL_c88e40281c2047c8a98f927aa6f2bb74"
            ]
          }
        },
        "246e80a145b640738dbd99a544cfc1f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_728b03bfa47c4c1ab869f8ec416a213c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7ea1a619db19497f9fe325b6086ebe97",
              "IPY_MODEL_1b065f79de324039b9e55a0edd00045e"
            ]
          }
        },
        "728b03bfa47c4c1ab869f8ec416a213c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7ea1a619db19497f9fe325b6086ebe97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a1fe665a815541d4a74e37af06bdce74",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d39795d9567e46b8be57846df17ab07b"
          }
        },
        "1b065f79de324039b9e55a0edd00045e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_087ba2773ac4482d9ca974f66693c71d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4514/? [1:31:01&lt;00:00,  1.21s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c422537f15b419eb09b75382353df2a"
          }
        },
        "a1fe665a815541d4a74e37af06bdce74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d39795d9567e46b8be57846df17ab07b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "087ba2773ac4482d9ca974f66693c71d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c422537f15b419eb09b75382353df2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08cd3cefda6440df9fbc10129071abbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2c488dcfaf9c4ec9938b25d55cd6f977",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_221e02af95934157a30595f9ca8eec76",
              "IPY_MODEL_56fd858dcbf841769f7b37dc2886e274"
            ]
          }
        },
        "2c488dcfaf9c4ec9938b25d55cd6f977": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "221e02af95934157a30595f9ca8eec76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_468c8b873c1c4286bbbc22b280b2d1ae",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d92e755f3ead45b39ffcacf0d0c853da"
          }
        },
        "56fd858dcbf841769f7b37dc2886e274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_391711d239444698841d45cbc07ae39d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4514/? [1:27:28&lt;00:00,  1.16s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e8d2263b9a4547208b1f1b27c03d9438"
          }
        },
        "468c8b873c1c4286bbbc22b280b2d1ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d92e755f3ead45b39ffcacf0d0c853da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "391711d239444698841d45cbc07ae39d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e8d2263b9a4547208b1f1b27c03d9438": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3609a35e85044448f0258524e843bd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8f87d69e5ac843d4ab53743be2cfd49a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9e61eca32c9341a3b0a33bdb02e129ad",
              "IPY_MODEL_e7dbeaf4ca324d4b9894a6b9bd19283a"
            ]
          }
        },
        "8f87d69e5ac843d4ab53743be2cfd49a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e61eca32c9341a3b0a33bdb02e129ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5c115ebc39274befb1e5d73c8b6689df",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a90059c49f0448d83c50fed25de279e"
          }
        },
        "e7dbeaf4ca324d4b9894a6b9bd19283a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b8b4139a75924f64b8f941679a9a17f5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 84/? [00:17&lt;00:00, 838.77it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2bb671826e574382b491dcf2785d10b2"
          }
        },
        "5c115ebc39274befb1e5d73c8b6689df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a90059c49f0448d83c50fed25de279e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8b4139a75924f64b8f941679a9a17f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2bb671826e574382b491dcf2785d10b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c3862762b7f48859bb6a13454399a7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7855ac719ec243c280fdb8d75888c016",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c4ccc49a76674d77b7c4a8babad50c76",
              "IPY_MODEL_74f70e232ea74e5a870c5d33c7caa0ca"
            ]
          }
        },
        "7855ac719ec243c280fdb8d75888c016": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c4ccc49a76674d77b7c4a8babad50c76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_43e78af42e6e486c9f84bba2104e9d81",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0ebdbdd185fb4c54a4d0f5b56bda512f"
          }
        },
        "74f70e232ea74e5a870c5d33c7caa0ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0f0abb4d73f2464ba9af9b227d15557e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/? [14:42&lt;00:00,  8.82s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f25e9bf0a4df40c0aa15f6f020d04b17"
          }
        },
        "43e78af42e6e486c9f84bba2104e9d81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0ebdbdd185fb4c54a4d0f5b56bda512f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f0abb4d73f2464ba9af9b227d15557e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f25e9bf0a4df40c0aa15f6f020d04b17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4MFL6d2PbUr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98b9bc2c-d8e8-45b8-83e4-3688e1928a71"
      },
      "source": [
        "# installing modules\n",
        "!pip install indic-nlp-library\n",
        "!pip install rouge-score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting indic-nlp-library\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/51/f4e4542a226055b73a621ad442c16ae2c913d6b497283c99cae7a9661e6c/indic_nlp_library-0.71-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from indic-nlp-library) (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from indic-nlp-library) (1.1.4)\n",
            "Collecting morfessor\n",
            "  Downloading https://files.pythonhosted.org/packages/39/e6/7afea30be2ee4d29ce9de0fa53acbb033163615f849515c0b1956ad074ee/Morfessor-2.0.6-py3-none-any.whl\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->indic-nlp-library) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->indic-nlp-library) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->indic-nlp-library) (1.15.0)\n",
            "Installing collected packages: morfessor, indic-nlp-library\n",
            "Successfully installed indic-nlp-library-0.71 morfessor-2.0.6\n",
            "Collecting rouge-score\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/56/a81022436c08b9405a5247b71635394d44fe7e1dbedc4b28c740e09c2840/rouge_score-0.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from rouge-score) (0.10.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from rouge-score) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from rouge-score) (1.18.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from rouge-score) (3.2.5)\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyDODoaWC6KI",
        "outputId": "4f99e0e2-bbd5-4851-91a2-32d98d46aba5"
      },
      "source": [
        "'''\n",
        "    Code for training transformer for the cross lingual summarization task\n",
        "'''\n",
        "import os\n",
        "import nltk\n",
        "import math\n",
        "import torch\n",
        "import torchtext\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchtext.vocab import Vectors\n",
        "from google.colab import drive\n",
        "from tqdm.notebook import tqdm\n",
        "from indicnlp.tokenize import indic_tokenize\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRHqYWo-nFy9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "607e14f2-e3de-4baf-acce-e72c9da838db"
      },
      "source": [
        "# setting up the configurations\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# setting the device variable\n",
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCO3ppx0nUru"
      },
      "source": [
        "# Fixing the fasttext class\n",
        "class FastText(Vectors):\n",
        "    new_url_base = 'https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.{}.vec'\n",
        "\n",
        "    def __init__(self, language=\"en\", **kwargs):\n",
        "        url = self.new_url_base.format(language)\n",
        "        name = os.path.basename(url)\n",
        "        super(FastText, self).__init__(name, url=url, **kwargs)\n",
        "\n",
        "# downloading the embeddings\n",
        "glove = torchtext.vocab.GloVe(name='6B', dim=300)\n",
        "fasttext_hindi = FastText(language='hi')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dvFnUvRrmNW"
      },
      "source": [
        "# tokenizers for both the languages\n",
        "def english_tokenize(sentence):\n",
        "    return [word.lower() for word in nltk.tokenize.word_tokenize(str(sentence))]\n",
        "\n",
        "def hindi_tokenize(sentence):\n",
        "    return indic_tokenize.trivial_tokenize(str(sentence), lang='hi')\n",
        "\n",
        "# parsing the dataset using the torchtext utility\n",
        "def parse_using_torchtext(csv_file_name, batch_size=16, english_vocab_size=10000, hindi_vocab_size=10000):\n",
        "\n",
        "    # defining the fields\n",
        "    english_field = torchtext.data.Field(\n",
        "        sequential=True,\n",
        "        init_token='<sos>',\n",
        "        eos_token='<eos>',\n",
        "        tokenize=english_tokenize,\n",
        "        batch_first=False\n",
        "    )\n",
        "    hindi_field = torchtext.data.Field(\n",
        "        sequential=True,\n",
        "        init_token='<sos>',\n",
        "        eos_token='<eos>',\n",
        "        tokenize=hindi_tokenize,\n",
        "        batch_first=False\n",
        "    )\n",
        "\n",
        "    # loading the data\n",
        "    train_data = torchtext.data.TabularDataset.splits(\n",
        "        path=os.path.dirname(csv_file_name),\n",
        "        train=os.path.basename(csv_file_name),\n",
        "        format='csv',\n",
        "        fields={'english_sentence': ('english_sentence', english_field), 'hindi_sentence': ('hindi_sentence', hindi_field)},\n",
        "        skip_header=False\n",
        "    )[0]\n",
        "\n",
        "    # building the vocabulary\n",
        "    english_field.build_vocab(train_data, max_size=english_vocab_size, min_freq=2)\n",
        "    hindi_field.build_vocab(train_data, max_size=hindi_vocab_size, min_freq=2)\n",
        "\n",
        "    # loading the bucket iterator\n",
        "    train_iterator = torchtext.data.BucketIterator.splits(\n",
        "        (train_data,),\n",
        "        (batch_size,),\n",
        "        device=device,\n",
        "        sort_key=lambda x: len(x.english_sentence)\n",
        "    )[0]\n",
        "\n",
        "    return english_field, hindi_field, train_data, train_iterator\n",
        "\n",
        "# construction of bucket iterator using predefined field\n",
        "def parse_using_field(csv_file_name, english_field, hindi_field, english_col_name, hindi_col_name, batch_size=16):\n",
        "    \n",
        "    # loading the data\n",
        "    train_data = torchtext.data.TabularDataset.splits(\n",
        "        path=os.path.dirname(csv_file_name),\n",
        "        train=os.path.basename(csv_file_name),\n",
        "        format='csv',\n",
        "        fields={english_col_name: ('english_sentence', english_field), hindi_col_name: ('hindi_sentence', hindi_field)},\n",
        "        skip_header=False\n",
        "    )[0]\n",
        "\n",
        "    # loading the bucket iterator\n",
        "    train_iterator = torchtext.data.BucketIterator.splits(\n",
        "        (train_data,),\n",
        "        (batch_size,),\n",
        "        device=device,\n",
        "        sort_key=lambda x: len(x.english_sentence)\n",
        "    )[0]\n",
        "\n",
        "    return train_data, train_iterator\n",
        "\n",
        "# for loading the dataset in an appropriate format\n",
        "def parse_dataset(csv_file_name, english_col_name, hindi_col_name, max_num=None):\n",
        "\n",
        "    # to be returned\n",
        "    english_sentences = []\n",
        "    hindi_sentences = []\n",
        "\n",
        "    # reading the csv file\n",
        "    csv_file_df = pd.read_csv(csv_file_name)\n",
        "\n",
        "    for index, row in tqdm(csv_file_df.iterrows()):\n",
        "        if max_num is not None and index == max_num:\n",
        "            break\n",
        "        english_sentences.append(english_tokenize(str(row[english_col_name])))\n",
        "        hindi_sentences.append(hindi_tokenize(str(row[hindi_col_name])))\n",
        "\n",
        "    return english_sentences, hindi_sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te326X4DfJM6"
      },
      "source": [
        "# some utility function\n",
        "def positional_encoding_1d(d_model, length):\n",
        "    \"\"\"\n",
        "    :param d_model: dimension of the model\n",
        "    :param length: length of positions\n",
        "    :return: length*d_model position matrix\n",
        "    \"\"\"\n",
        "    if d_model % 2 != 0:\n",
        "        raise ValueError(\"Cannot use sin/cos positional encoding with \"\n",
        "                         \"odd dim (got dim={:d})\".format(d_model))\n",
        "    pe = torch.zeros(length, d_model)\n",
        "    position = torch.arange(0, length).unsqueeze(1)\n",
        "    div_term = torch.exp((torch.arange(0, d_model, 2, dtype=torch.float) *\n",
        "                         -(math.log(10000.0) / d_model)))\n",
        "    pe[:, 0::2] = torch.sin(position.float() * div_term)\n",
        "    pe[:, 1::2] = torch.cos(position.float() * div_term)\n",
        "\n",
        "    return pe\n",
        "\n",
        "# model definition\n",
        "class CustomTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        english_embedding,\n",
        "        english_vocab,\n",
        "        hindi_embedding,\n",
        "        hindi_vocab,\n",
        "        num_heads=8,\n",
        "        num_encoder_layers=6,\n",
        "        num_decoder_layers=6,\n",
        "        dropout=0.1,\n",
        "        multitask=False\n",
        "    ):\n",
        "        super(CustomTransformer, self).__init__()\n",
        "\n",
        "        # storing the input arguments\n",
        "        self.english_vocab = english_vocab\n",
        "        self.hindi_vocab = hindi_vocab\n",
        "        self.english_embedding = english_embedding\n",
        "        self.hindi_embedding = hindi_embedding\n",
        "\n",
        "        # extracting the embeddings weights\n",
        "        english_embedding_weight = torch.zeros(len(english_vocab.itos), english_embedding.dim, dtype=torch.float)\n",
        "        hindi_embedding_weight = torch.zeros(len(hindi_vocab.itos), hindi_embedding.dim, dtype=torch.float)\n",
        "        for word_id in range(len(english_vocab.itos)):\n",
        "            english_embedding_weight[word_id] = english_embedding[english_vocab.itos[word_id]]\n",
        "        for word_id in range(len(hindi_vocab.itos)):\n",
        "            hindi_embedding_weight[word_id] = hindi_embedding[hindi_vocab.itos[word_id]]\n",
        "\n",
        "        # initializing the embeddings\n",
        "        self.english_word_embedding = nn.Embedding.from_pretrained(english_embedding_weight, padding_idx=english_vocab.stoi['<pad>'], freeze=False)\n",
        "        self.hindi_word_embedding = nn.Embedding.from_pretrained(hindi_embedding_weight, padding_idx=hindi_vocab.stoi['<pad>'], freeze=False)\n",
        "\n",
        "        # initializing the transformer\n",
        "        self.english_pad_index = english_vocab.stoi['<pad>']\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc_out = nn.Linear(hindi_embedding.dim, len(hindi_vocab.stoi.keys()))\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=english_embedding.dim,\n",
        "            nhead=num_heads,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "    # for creating the english mask\n",
        "    def make_english_mask(self, english_batch):\n",
        "        english_mask = english_batch.transpose(0, 1) == self.english_pad_index\n",
        "        return english_mask\n",
        "\n",
        "    # forward pass\n",
        "    def forward(self, english_batch, hindi_batch):\n",
        "        \n",
        "        # retrieving the length and checking for correctness\n",
        "        english_seq_length, batch_size_english = english_batch.shape\n",
        "        hindi_seq_length, batch_size_hindi = hindi_batch.shape\n",
        "        assert(batch_size_english == batch_size_hindi)\n",
        "        batch_size = batch_size_english\n",
        "        \n",
        "        # forming the positional embedding\n",
        "        english_pos_embedding = positional_encoding_1d(self.english_word_embedding.embedding_dim, english_seq_length)\n",
        "        hindi_pos_embedding = positional_encoding_1d(self.hindi_word_embedding.embedding_dim, hindi_seq_length)\n",
        "        english_pos_embedding = english_pos_embedding.expand(batch_size, english_seq_length, self.english_word_embedding.embedding_dim).transpose(0, 1)\n",
        "        hindi_pos_embedding = hindi_pos_embedding.expand(batch_size, hindi_seq_length, self.hindi_word_embedding.embedding_dim).transpose(0, 1)\n",
        "\n",
        "        # producing the final embedding\n",
        "        english_final_embedding = self.dropout(self.english_word_embedding(english_batch) + english_pos_embedding.to(device))\n",
        "        hindi_final_embedding = self.dropout(self.hindi_word_embedding(hindi_batch) + hindi_pos_embedding.to(device))\n",
        "\n",
        "        # producing the masks\n",
        "        english_padding_mask = self.make_english_mask(english_batch).to(device)\n",
        "        hindi_mask = self.transformer.generate_square_subsequent_mask(hindi_seq_length).to(device)\n",
        "\n",
        "        # getting the output\n",
        "        output = self.transformer(\n",
        "            english_final_embedding,\n",
        "            hindi_final_embedding,\n",
        "            src_key_padding_mask=english_padding_mask,\n",
        "            tgt_mask=hindi_mask\n",
        "        )\n",
        "\n",
        "        return self.fc_out(output)\n",
        "\n",
        "# function for training the model\n",
        "def train_transformer(model, train_iterator, pad_index, num_epoches=1000, learning_rate=1e-4, save_name=None):\n",
        "\n",
        "    # sentence to be tested\n",
        "    english_sentence = 'a horse goes under a bridge next to a boat.'\n",
        "\n",
        "    # initializing the optimizers and loss class\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
        "\n",
        "    # training begins\n",
        "    for epoch in tqdm(range(num_epoches)):\n",
        "        total_loss = 0\n",
        "\n",
        "        model.train()\n",
        "        for batch_index, batch in tqdm(enumerate(train_iterator)):\n",
        "            \n",
        "            # clearing the gradient buffer\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # extracting the example\n",
        "            english_batch = batch.english_sentence.to(device)\n",
        "            hindi_batch = batch.hindi_sentence.to(device)\n",
        "\n",
        "            # forward propagation\n",
        "            predict_logits = model(english_batch, hindi_batch[:-1, :])\n",
        "            predict_logits = predict_logits.reshape(-1, predict_logits.shape[2])\n",
        "            actual_hindi_batch = hindi_batch[1:].reshape(-1)\n",
        "\n",
        "            # backward propagation\n",
        "            loss = criterion(predict_logits, actual_hindi_batch)\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                total_loss += loss.detach().item()\n",
        "\n",
        "            # deleting to save GPU memory\n",
        "            del english_batch\n",
        "            del hindi_batch\n",
        "            del predict_logits\n",
        "            del actual_hindi_batch\n",
        "            del loss\n",
        "            del batch, batch_index\n",
        "\n",
        "        # making changes to the optimizer\n",
        "        print('Loss at {}th epoch: {}'.format(epoch, total_loss))\n",
        "        scheduler.step(total_loss)\n",
        "\n",
        "        # testing the model\n",
        "        hindi_tokens = produce_output(model, english_sentence)\n",
        "        print(english_sentence, '-', ' '.join(hindi_tokens))\n",
        "\n",
        "        # saving the file\n",
        "        if save_name is not None:\n",
        "            torch.save(model.state_dict(), save_name)\n",
        "\n",
        "# function for producing the output sentence for a given input\n",
        "def produce_output(model, sentence, max_length=100):\n",
        "\n",
        "    # tokenization using custom function\n",
        "    if type(sentence) == str:\n",
        "        tokens = english_tokenize(sentence)\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    # Add <SOS> and <EOS> in beginning and end respectively\n",
        "    tokens.insert(0, '<sos>')\n",
        "    tokens.append('<eos>')\n",
        "\n",
        "    # Go through each english token and convert to an index\n",
        "    text_to_indices = [model.english_vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    # Convert to Tensor\n",
        "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
        "\n",
        "    outputs = [model.hindi_vocab.stoi[\"<sos>\"]]\n",
        "    for i in range(max_length):\n",
        "        trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            output = model(sentence_tensor, trg_tensor)\n",
        "\n",
        "        best_guess = output.argmax(2)[-1, :].item()\n",
        "        outputs.append(best_guess)\n",
        "\n",
        "        if best_guess == model.hindi_vocab.stoi[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    translated_sentence = [model.hindi_vocab.itos[idx] for idx in outputs]\n",
        "\n",
        "    # remove start token\n",
        "    return translated_sentence[1:]\n",
        "\n",
        "# utilities for performance computation\n",
        "def report_performance(model, english_sentences, hindi_sentences):\n",
        "\n",
        "    # initializing the ROUGE scorer\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "    # quantities to be returned\n",
        "    average_bleu = 0\n",
        "    average_rouge1 = 0\n",
        "    average_rougeL = 0\n",
        "\n",
        "    for (english_sentence, hindi_sentence) in tqdm(zip(english_sentences, hindi_sentences)):\n",
        "        output_sentence = produce_output(model, english_sentence)\n",
        "\n",
        "        # bleu score\n",
        "        average_bleu += nltk.translate.bleu_score.sentence_bleu([hindi_sentence], output_sentence[:-1])\n",
        "\n",
        "        # rouge_scores\n",
        "        rouge_obj = scorer.score(' '.join(hindi_sentence), ' '.join(output_sentence[:-1]))\n",
        "        average_rouge1 += rouge_obj['rouge1'].recall\n",
        "        average_rougeL += rouge_obj['rougeL'].recall\n",
        "\n",
        "    # normalizing\n",
        "    n = len(hindi_sentences)\n",
        "    return {'bleu_score': average_bleu / n, 'rouge1_score': average_rouge1 / n, 'rougeL_score': average_rougeL / n}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYZ_9NJn7GGd"
      },
      "source": [
        "### Pretraining the Baseline Transformer for Machine Translation Task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c77ee2p0v7pM"
      },
      "source": [
        "# for pretraining using hindEnCorp parallel corpus\n",
        "english_field, hindi_field, train_data, train_iterator = parse_using_torchtext('drive/MyDrive/cs626_dataset/Hindi_English_Truncated_Corpus.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ni7kZb8hOj0",
        "outputId": "acfa0184-7ec6-4378-8bfc-d3ae42e3cc5d"
      },
      "source": [
        "# testing with model\n",
        "transformer = CustomTransformer(glove, english_field.vocab, fasttext_hindi, hindi_field.vocab, num_heads=6).to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "eb81b90864144cd5adecce819b7483b2",
            "d7916a6d0e0842489cc12a70ccdb4ad0",
            "a6f6f17bb9c5401ca8b5f2ebfca3721f",
            "c88e40281c2047c8a98f927aa6f2bb74",
            "c3fff036c5f2486a94522992e05716ed",
            "7a86098bf35644dcb6bb6e881b2d4e4d"
          ]
        },
        "id": "y90QURRR0uXL",
        "outputId": "6b96db2a-1c4a-4b15-fe95-b8ab4de27062"
      },
      "source": [
        "# testing the training procedure (80 done)\n",
        "train_transformer(transformer, train_iterator, english_field.vocab.stoi['<pad>'], num_epoches=20, save_name='/content/drive/MyDrive/cs626_dataset/transformer_6_6_6.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb81b90864144cd5adecce819b7483b2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3fff036c5f2486a94522992e05716ed",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loss at 0th epoch: 5427.155629694462\n",
            "a horse goes under a bridge next to a boat. - जहाज के नीचे भरत की ओर <unk> है . <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a86098bf35644dcb6bb6e881b2d4e4d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKuy9xQP7TAB"
      },
      "source": [
        "## Fine tuning of the Baseline Transformer for Cross lingual Summarization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qixh5vgxmsHV"
      },
      "source": [
        "'''\n",
        "    Training the model for cross lingual summarizaton\n",
        "'''\n",
        "\n",
        "# parsing the dataset\n",
        "train_cls_data, train_cls_iterator = parse_using_field('drive/MyDrive/cs626_dataset/CLS_dataset.csv', english_field, hindi_field, 'text', 'summary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7sCoFI0msgS"
      },
      "source": [
        "# training the transformer for cross lingual summarization\n",
        "train_transformer(transformer, train_cls_iterator, english_field.vocab.stoi['<pad>'], num_epoches=20, save_name='/content/drive/MyDrive/cs626_dataset/transformer_6_6_6_cls.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0X1Twx3i5w06"
      },
      "source": [
        "### Performance of the Baseline Transformer for Cross Lingual Summarization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366,
          "referenced_widgets": [
            "246e80a145b640738dbd99a544cfc1f9",
            "728b03bfa47c4c1ab869f8ec416a213c",
            "7ea1a619db19497f9fe325b6086ebe97",
            "1b065f79de324039b9e55a0edd00045e",
            "a1fe665a815541d4a74e37af06bdce74",
            "d39795d9567e46b8be57846df17ab07b",
            "087ba2773ac4482d9ca974f66693c71d",
            "4c422537f15b419eb09b75382353df2a",
            "08cd3cefda6440df9fbc10129071abbb",
            "2c488dcfaf9c4ec9938b25d55cd6f977",
            "221e02af95934157a30595f9ca8eec76",
            "56fd858dcbf841769f7b37dc2886e274",
            "468c8b873c1c4286bbbc22b280b2d1ae",
            "d92e755f3ead45b39ffcacf0d0c853da",
            "391711d239444698841d45cbc07ae39d",
            "e8d2263b9a4547208b1f1b27c03d9438"
          ]
        },
        "id": "dbqzFqBSxIi4",
        "outputId": "99d63992-1436-4a91-ac12-588cb6545312"
      },
      "source": [
        "# loading the dataset in the form of tokens\r\n",
        "english_sentences, hindi_sentences = parse_dataset('drive/MyDrive/cs626_dataset/CLS_dataset_test.csv', 'text', 'summary')\r\n",
        "\r\n",
        "# loading the model\r\n",
        "transformer = CustomTransformer(glove, english_field.vocab, fasttext_hindi, hindi_field.vocab, num_heads=6).to(device)\r\n",
        "transformer.load_state_dict(torch.load('drive/MyDrive/cs626_dataset/transformer_6_6_6_cls.pt', map_location=device))\r\n",
        "\r\n",
        "# obtaining the results\r\n",
        "report_performance(transformer, english_sentences, hindi_sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "246e80a145b640738dbd99a544cfc1f9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08cd3cefda6440df9fbc10129071abbb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bleu_score': 0.41357651166166304,\n",
              " 'rouge1_score': 0.09561944848830092,\n",
              " 'rougeL_score': 0.0955456041521615}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2x9avYCicdF"
      },
      "source": [
        "### Some examples of the Baseline Transformer Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptfZrDcaimU4"
      },
      "source": [
        "##### The Bombay High Court on Monday summoned the Maharashtra Women and Child Development Secretary after 42 children went missing over the last three years from a Mumbai remand home. The court criticised the Maharashtra government for lack of 'pro-active action' in the matter. The Bombay High Court is hearing a PIL on the allegations of corruption in the remand home."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c7YjSYQ4vDZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5296be78-76d7-4a1d-84ee-76ce696d5a85"
      },
      "source": [
        "' '.join(produce_output(transformer, \"The Bombay High Court on Monday summoned the Maharashtra Women and Child Development Secretary after 42 children went missing over the last three years from a Mumbai remand home. The court criticised the Maharashtra government for lack of 'pro-active action' in the matter. The Bombay High Court is hearing a PIL on the allegations of corruption in the remand home.\")[:-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'42 बच्चों के घर से बाहर निकलने के बाद बॉम्बे <unk> ने सचिव को बुलाया'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZDci1gtkGuM"
      },
      "source": [
        "#####As many as 76 passengers were rescued from cable cars suspended over a river in German city Cologne after a gondola crashed into a support pillar on Sunday. Passengers were left stranded, and children were seen clinging to parents while dangling as many as 40 metres above the river. The fire department lowered them to safety from the cable cars"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yCHpqhkn4yVX",
        "outputId": "d9621b32-93e8-47c8-8afa-422948896a5f"
      },
      "source": [
        "' '.join(produce_output(transformer, \"As many as 76 passengers were rescued from cable cars suspended over a river in German city Cologne after a gondola crashed into a support pillar on Sunday. Passengers were left stranded, and children were seen clinging to parents while dangling as many as 40 metres above the river. The fire department lowered them to safety from the cable cars\")[:-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'केबल कार <unk> से उतरने के बाद 76 यात्री निलंबित'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWA9QrtVkoqI"
      },
      "source": [
        "#####An 11-year-old tribal boy allegedly committed suicide on Tuesday by hanging himself near his school, after he was caught stealing ?30 from his classmate in Maharashtra's Mokhada. The boy was reportedly ashamed of his act and had tried to force a classmate to commit suicide with him, but he refused. Police said the boy has a history of criminal activities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV51lekUD9NB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e602eb78-9e7e-4527-d9c5-0622b39ae80c"
      },
      "source": [
        "' '.join(produce_output(transformer, \"An 11-year-old tribal boy allegedly committed suicide on Tuesday by hanging himself near his school, after he was caught stealing ?30 from his classmate in Maharashtra's Mokhada. The boy was reportedly ashamed of his act and had tried to force a classmate to commit suicide with him, but he refused. Police said the boy has a history of criminal activities.\")[:-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'19 - वर्षीय आदिवासी लड़के ने <unk> पकड़ा , 30 से 30 पकड़े जाने के बाद आत्म हत्या कर ली'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJ9QBwZLlWUf"
      },
      "source": [
        "#####Four labourers on Monday were reportedly injured after a tree branch fell on them at Dombivli station road in Mumbai. They were admitted to hospital with injuries and were later declared out of danger. Reportedly, tree fall cases are on rise in Kalyan-Dombivli. \"\"Last year fewer cases were reported. We have been getting complaints of tree falls daily,\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cCoewkg9kvPz",
        "outputId": "be35146e-9d28-4f20-b942-8a5d9bf75aec"
      },
      "source": [
        "' '.join(produce_output(transformer, \"Four labourers on Monday were reportedly injured after a tree branch fell on them at Dombivli station road in Mumbai. They were admitted to hospital with injuries and were later declared out of danger. Reportedly, tree fall cases are on rise in Kalyan-Dombivli. Last year fewer cases were reported. We have been getting complaints of tree falls daily\")[:-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'मुंबई में पेड़ की शाखा गिरने से 4 मजदूर घायल हो गए'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1BSj8RFmR8t"
      },
      "source": [
        "### Multitasking objective transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z5QhorWleQc"
      },
      "source": [
        "class MultitaskTransformer(nn.Module):\r\n",
        "    def __init__(\r\n",
        "        self,\r\n",
        "        english_embedding,\r\n",
        "        english_vocab,\r\n",
        "        hindi_embedding,\r\n",
        "        hindi_vocab,\r\n",
        "        num_heads=8,\r\n",
        "        num_encoder_layers=6,\r\n",
        "        num_decoder_layers=6,\r\n",
        "        dropout=0.1,\r\n",
        "    ):\r\n",
        "        super(MultitaskTransformer, self).__init__()\r\n",
        "\r\n",
        "        # storing the input arguments\r\n",
        "        self.english_vocab = english_vocab\r\n",
        "        self.hindi_vocab = hindi_vocab\r\n",
        "        self.english_embedding = english_embedding\r\n",
        "        self.hindi_embedding = hindi_embedding\r\n",
        "\r\n",
        "        # extracting the embeddings weights\r\n",
        "        english_embedding_weight = torch.zeros(len(english_vocab.itos), english_embedding.dim, dtype=torch.float)\r\n",
        "        hindi_embedding_weight = torch.zeros(len(hindi_vocab.itos), hindi_embedding.dim, dtype=torch.float)\r\n",
        "        for word_id in range(len(english_vocab.itos)):\r\n",
        "            english_embedding_weight[word_id] = english_embedding[english_vocab.itos[word_id]]\r\n",
        "        for word_id in range(len(hindi_vocab.itos)):\r\n",
        "            hindi_embedding_weight[word_id] = hindi_embedding[hindi_vocab.itos[word_id]]\r\n",
        "\r\n",
        "        # initializing the embeddings\r\n",
        "        self.english_word_embedding = nn.Embedding.from_pretrained(english_embedding_weight, padding_idx=english_vocab.stoi['<pad>'], freeze=False)\r\n",
        "        self.hindi_word_embedding = nn.Embedding.from_pretrained(hindi_embedding_weight, padding_idx=hindi_vocab.stoi['<pad>'], freeze=False)\r\n",
        "\r\n",
        "        # initializing a single encoder\r\n",
        "        encoder_layer = nn.TransformerEncoderLayer(english_embedding.dim, num_heads, dropout=dropout)\r\n",
        "        encoder_norm = nn.LayerNorm(english_embedding.dim)\r\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_encoder_layers, encoder_norm)\r\n",
        "\r\n",
        "        # machine translation decoder\r\n",
        "        mt_decoder_layer = nn.TransformerDecoderLayer(hindi_embedding.dim, num_heads, dropout=dropout)\r\n",
        "        mt_decoder_norm = nn.LayerNorm(hindi_embedding.dim)\r\n",
        "        self.mt_decoder = nn.TransformerDecoder(mt_decoder_layer, num_decoder_layers, mt_decoder_norm)\r\n",
        "\r\n",
        "        # cross lingual summarization decoder\r\n",
        "        cls_decoder_layer = nn.TransformerDecoderLayer(hindi_embedding.dim, num_heads, dropout=dropout)\r\n",
        "        cls_decoder_norm = nn.LayerNorm(hindi_embedding.dim)\r\n",
        "        self.cls_decoder = nn.TransformerDecoder(cls_decoder_layer, num_decoder_layers, cls_decoder_norm)\r\n",
        "\r\n",
        "        # Feed forward initializations\r\n",
        "        self.english_pad_index = english_vocab.stoi['<pad>']\r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        self.mt_fc_out = nn.Linear(hindi_embedding.dim, len(hindi_vocab.stoi.keys()))\r\n",
        "        self.cls_fc_out = nn.Linear(hindi_embedding.dim, len(hindi_vocab.stoi.keys()))\r\n",
        "\r\n",
        "    # for creating the english mask\r\n",
        "    def make_english_mask(self, english_batch):\r\n",
        "        english_mask = english_batch.transpose(0, 1) == self.english_pad_index\r\n",
        "        return english_mask\r\n",
        "\r\n",
        "    def generate_square_subsequent_mask(self, sz):\r\n",
        "        r\"\"\"Generate a square mask for the sequence. The masked positions are filled with float('-inf').\r\n",
        "            Unmasked positions are filled with float(0.0).\r\n",
        "        \"\"\"\r\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\r\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\r\n",
        "        return mask\r\n",
        "\r\n",
        "    # forward pass\r\n",
        "    def forward(self, english_batch, hindi_batch, mode='cls'):\r\n",
        "        \r\n",
        "        # retrieving the length and checking for correctness\r\n",
        "        english_seq_length, batch_size_english = english_batch.shape\r\n",
        "        hindi_seq_length, batch_size_hindi = hindi_batch.shape\r\n",
        "        assert(batch_size_english == batch_size_hindi)\r\n",
        "        batch_size = batch_size_english\r\n",
        "        \r\n",
        "        # forming the positional embedding\r\n",
        "        english_pos_embedding = positional_encoding_1d(self.english_word_embedding.embedding_dim, english_seq_length)\r\n",
        "        hindi_pos_embedding = positional_encoding_1d(self.hindi_word_embedding.embedding_dim, hindi_seq_length)\r\n",
        "        english_pos_embedding = english_pos_embedding.expand(batch_size, english_seq_length, self.english_word_embedding.embedding_dim).transpose(0, 1)\r\n",
        "        hindi_pos_embedding = hindi_pos_embedding.expand(batch_size, hindi_seq_length, self.hindi_word_embedding.embedding_dim).transpose(0, 1)\r\n",
        "\r\n",
        "        # producing the final embedding\r\n",
        "        english_final_embedding = self.dropout(self.english_word_embedding(english_batch) + english_pos_embedding.to(device))\r\n",
        "        hindi_final_embedding = self.dropout(self.hindi_word_embedding(hindi_batch) + hindi_pos_embedding.to(device))\r\n",
        "\r\n",
        "        # producing the masks\r\n",
        "        english_padding_mask = self.make_english_mask(english_batch).to(device)\r\n",
        "        hindi_mask = self.generate_square_subsequent_mask(hindi_seq_length).to(device)\r\n",
        "\r\n",
        "        # getting the output\r\n",
        "        memory = self.encoder(english_final_embedding, src_key_padding_mask=english_padding_mask)\r\n",
        "        if mode == 'cls':\r\n",
        "            output = self.cls_decoder(hindi_final_embedding, memory, tgt_mask=hindi_mask)\r\n",
        "            return self.cls_fc_out(output)\r\n",
        "        elif mode == 'mt':\r\n",
        "            output = self.mt_decoder(hindi_final_embedding, memory, tgt_mask=hindi_mask)\r\n",
        "            return self.mt_fc_out(output)\r\n",
        "\r\n",
        "# function for training the multi task transformer\r\n",
        "def train_multitask_transformer(model, mt_iterator, cls_iterator, pad_index, num_epoches=1000, learning_rate=1e-4, save_name=None):\r\n",
        "\r\n",
        "    # sentence to be tested\r\n",
        "    english_sentence = 'a horse goes under a bridge next to a boat.'\r\n",
        "\r\n",
        "    # initializing the optimizers and loss class\r\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\r\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True)\r\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=pad_index)\r\n",
        "\r\n",
        "    # training begins\r\n",
        "    for epoch in tqdm(range(num_epoches)):\r\n",
        "        total_loss = 0\r\n",
        "        total_mt_loss = 0\r\n",
        "        total_cls_loss = 0\r\n",
        "        model.train()\r\n",
        "        for batch_index, mt_batch in tqdm(enumerate(mt_iterator)):\r\n",
        "            \r\n",
        "            # clearing the gradient buffer\r\n",
        "            optimizer.zero_grad()\r\n",
        "\r\n",
        "            # extracting the example\r\n",
        "            cls_batch = next(iter(cls_iterator))\r\n",
        "            cls_english_batch = cls_batch.english_sentence.to(device)\r\n",
        "            cls_hindi_batch = cls_batch.hindi_sentence.to(device)\r\n",
        "            mt_english_batch = mt_batch.english_sentence.to(device)\r\n",
        "            mt_hindi_batch = mt_batch.hindi_sentence.to(device)\r\n",
        "\r\n",
        "            # forward propagation\r\n",
        "            mt_predict_logits = model(mt_english_batch, mt_hindi_batch[:-1, :], mode='mt')\r\n",
        "            mt_predict_logits = mt_predict_logits.reshape(-1, mt_predict_logits.shape[2])\r\n",
        "            mt_actual_hindi_batch = mt_hindi_batch[1:].reshape(-1)\r\n",
        "            cls_predict_logits = model(cls_english_batch, cls_hindi_batch[:-1, :], mode='cls')\r\n",
        "            cls_predict_logits = cls_predict_logits.reshape(-1, cls_predict_logits.shape[2])\r\n",
        "            cls_actual_hindi_batch = cls_hindi_batch[1:].reshape(-1)\r\n",
        "\r\n",
        "            # backward propagation\r\n",
        "            mt_loss = criterion(mt_predict_logits, mt_actual_hindi_batch)\r\n",
        "            cls_loss = criterion(cls_predict_logits, cls_actual_hindi_batch) \r\n",
        "            loss = mt_loss + cls_loss\r\n",
        "            loss.backward()\r\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\r\n",
        "            optimizer.step()\r\n",
        "            \r\n",
        "            with torch.no_grad():\r\n",
        "                total_loss += loss.detach().item()\r\n",
        "                total_mt_loss += mt_loss.detach().item()\r\n",
        "                total_cls_loss += cls_loss.detach().item()\r\n",
        "\r\n",
        "            # deleting to save GPU memory\r\n",
        "            del mt_english_batch, cls_english_batch\r\n",
        "            del mt_hindi_batch, cls_hindi_batch \r\n",
        "            del mt_predict_logits, cls_predict_logits\r\n",
        "            del mt_actual_hindi_batch, cls_actual_hindi_batch\r\n",
        "            del loss\r\n",
        "            del mt_batch, cls_batch, batch_index\r\n",
        "\r\n",
        "        # making changes to the optimizer\r\n",
        "        print('Loss at {}th epoch: {}'.format(epoch, total_loss))\r\n",
        "        print('MT: {}'.format(total_mt_loss))\r\n",
        "        print('CLS: {}'.format(total_cls_loss))\r\n",
        "        scheduler.step(total_loss)\r\n",
        "\r\n",
        "        # testing the model\r\n",
        "        hindi_tokens = produce_output(model, english_sentence)\r\n",
        "        print(english_sentence, '-', ' '.join(hindi_tokens))\r\n",
        "\r\n",
        "        # saving the file\r\n",
        "        if save_name is not None:\r\n",
        "            torch.save(model.state_dict(), save_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cdc4fcabxs20"
      },
      "source": [
        "### Training the Multi task transformer\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijR0jgMMxqC_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3125bf63-678c-4278-81be-94d5ba748107"
      },
      "source": [
        "english_field, hindi_field, mt_train_data, mt_train_iterator = parse_using_torchtext('drive/MyDrive/cs626_dataset/Hindi_English_Truncated_Corpus.csv', 16, 20000, 20000)\r\n",
        "cls_train_data, cls_train_iterator = parse_using_field('drive/MyDrive/cs626_dataset/CLS_dataset.csv', english_field, hindi_field, 'text', 'summary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|█████████▉| 157992/158016 [00:35<00:00, 9004.34it/s]\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NPzrfARyHfH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0c39161-d871-4c8b-c526-5d837c580985"
      },
      "source": [
        "# initializing the multitask transformer\r\n",
        "transformer = MultitaskTransformer(glove, english_field.vocab, fasttext_hindi, hindi_field.vocab, num_heads=6).to(device)\r\n",
        "transformer.load_state_dict(torch.load('/content/drive/MyDrive/cs626_dataset/multitasktransformer_6_6_6_cls.pt', map_location=device))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg_60fLcy94s"
      },
      "source": [
        "train_multitask_transformer(transformer, mt_train_iterator, cls_train_iterator, english_field.vocab.stoi['<pad>'], num_epoches=60, save_name='/content/drive/MyDrive/cs626_dataset/multitasktransformer_6_6_6_cls.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O87aQyW80XV-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350,
          "referenced_widgets": [
            "b3609a35e85044448f0258524e843bd6",
            "8f87d69e5ac843d4ab53743be2cfd49a",
            "9e61eca32c9341a3b0a33bdb02e129ad",
            "e7dbeaf4ca324d4b9894a6b9bd19283a",
            "5c115ebc39274befb1e5d73c8b6689df",
            "1a90059c49f0448d83c50fed25de279e",
            "b8b4139a75924f64b8f941679a9a17f5",
            "2bb671826e574382b491dcf2785d10b2",
            "9c3862762b7f48859bb6a13454399a7f",
            "7855ac719ec243c280fdb8d75888c016",
            "c4ccc49a76674d77b7c4a8babad50c76",
            "74f70e232ea74e5a870c5d33c7caa0ca",
            "43e78af42e6e486c9f84bba2104e9d81",
            "0ebdbdd185fb4c54a4d0f5b56bda512f",
            "0f0abb4d73f2464ba9af9b227d15557e",
            "f25e9bf0a4df40c0aa15f6f020d04b17"
          ]
        },
        "outputId": "faee5752-f422-4b66-dcc2-b5fdfe4b3fb4"
      },
      "source": [
        "# loading the dataset in the form of tokens\r\n",
        "english_sentences, hindi_sentences = parse_dataset('drive/MyDrive/cs626_dataset/CLS_dataset_test.csv', 'text', 'summary', max_num=100)\r\n",
        "\r\n",
        "# obtaining the results\r\n",
        "report_performance(transformer, english_sentences, hindi_sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3609a35e85044448f0258524e843bd6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c3862762b7f48859bb6a13454399a7f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bleu_score': 0.3406240250489478,\n",
              " 'rouge1_score': 0.015,\n",
              " 'rougeL_score': 0.015}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL6RnrCfAbSc"
      },
      "source": [
        "### Demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WKnTCnD1Vue"
      },
      "source": [
        "# for pretraining using hindEnCorp parallel corpus\r\n",
        "english_field, hindi_field, train_data, train_iterator = parse_using_torchtext('drive/MyDrive/cs626_dataset/Hindi_English_Truncated_Corpus.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLVKZo901ZVt"
      },
      "source": [
        "# testing with model\r\n",
        "transformer = CustomTransformer(glove, english_field.vocab, fasttext_hindi, hindi_field.vocab, num_heads=6).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZs3zoIYBXg1",
        "outputId": "e4d42993-63bb-4602-c2b2-fd5ee6fe7fd8"
      },
      "source": [
        "# loading the pretrained model\r\n",
        "transformer.load_state_dict(torch.load('drive/MyDrive/cs626_dataset/transformer_6_6_6_cls.pt', map_location=device))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "txYcfA6hBrxI",
        "outputId": "4e7211a5-942e-4869-b757-b3f61cb7b2cf"
      },
      "source": [
        "# output example\r\n",
        "' '.join(produce_output(transformer, 'The Ghaziabad Police has booked 14 people including 3 Congress workers for resorting to violence during protests in front of the Ala Hazrat Haj House on Monday. Nearly 500 protesters had pelted stones at the police during the protest demanding that the facility be opened to pilgrims immediately. The facility has remained sealed since its inauguration last year.')[:-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<unk> हज हाउस के सामने हिंसा भड़काने के लिए <unk> पुलिस ने <unk> की'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    }
  ]
}